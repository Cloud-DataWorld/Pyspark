{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7332ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b20ffca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+------+------+----+\n",
      "| id|     name|gender|salary|Dept|\n",
      "+---+---------+------+------+----+\n",
      "|  1|     srik|  male|  2000|   2|\n",
      "|  2|     manu|  male|  3000|   1|\n",
      "|  3|Akshainie|Female|  3000|   4|\n",
      "+---+---------+------+------+----+\n",
      "\n",
      "+---+-------+\n",
      "| id|   Name|\n",
      "+---+-------+\n",
      "|  1|     IT|\n",
      "|  2|     HR|\n",
      "|  3|Payroll|\n",
      "+---+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = [(1,'srik','male',2000,2),\\\n",
    "        (2,'manu','male',3000,1),\\\n",
    "       (3,'Akshainie','Female',3000,4)] \n",
    "\n",
    "schema = ['id','name','gender','salary','Dept']\n",
    "\n",
    "df = spark.createDataFrame(data,schema)\n",
    "\n",
    "df.show()\n",
    "\n",
    "data1 = [(1,'IT'),\\\n",
    "        (2,'HR'),\\\n",
    "        (3,'Payroll')]\n",
    "\n",
    "schema1 = ['id','Name']\n",
    "\n",
    "df1 = spark.createDataFrame(data1,schema1)\n",
    "\n",
    "df1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1815469e",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method join in module pyspark.sql.dataframe:\n",
      "\n",
      "join(other, on=None, how=None) method of pyspark.sql.dataframe.DataFrame instance\n",
      "    Joins with another :class:`DataFrame`, using the given join expression.\n",
      "    \n",
      "    .. versionadded:: 1.3.0\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    other : :class:`DataFrame`\n",
      "        Right side of the join\n",
      "    on : str, list or :class:`Column`, optional\n",
      "        a string for the join column name, a list of column names,\n",
      "        a join expression (Column), or a list of Columns.\n",
      "        If `on` is a string or a list of strings indicating the name of the join column(s),\n",
      "        the column(s) must exist on both sides, and this performs an equi-join.\n",
      "    how : str, optional\n",
      "        default ``inner``. Must be one of: ``inner``, ``cross``, ``outer``,\n",
      "        ``full``, ``fullouter``, ``full_outer``, ``left``, ``leftouter``, ``left_outer``,\n",
      "        ``right``, ``rightouter``, ``right_outer``, ``semi``, ``leftsemi``, ``left_semi``,\n",
      "        ``anti``, ``leftanti`` and ``left_anti``.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    The following performs a full outer join between ``df1`` and ``df2``.\n",
      "    \n",
      "    >>> from pyspark.sql.functions import desc\n",
      "    >>> df.join(df2, df.name == df2.name, 'outer').select(df.name, df2.height)                 .sort(desc(\"name\")).collect()\n",
      "    [Row(name='Bob', height=85), Row(name='Alice', height=None), Row(name=None, height=80)]\n",
      "    \n",
      "    >>> df.join(df2, 'name', 'outer').select('name', 'height').sort(desc(\"name\")).collect()\n",
      "    [Row(name='Tom', height=80), Row(name='Bob', height=85), Row(name='Alice', height=None)]\n",
      "    \n",
      "    >>> cond = [df.name == df3.name, df.age == df3.age]\n",
      "    >>> df.join(df3, cond, 'outer').select(df.name, df3.age).collect()\n",
      "    [Row(name='Alice', age=2), Row(name='Bob', age=5)]\n",
      "    \n",
      "    >>> df.join(df2, 'name').select(df.name, df2.height).collect()\n",
      "    [Row(name='Bob', height=85)]\n",
      "    \n",
      "    >>> df.join(df4, ['name', 'age']).select(df.name, df.age).collect()\n",
      "    [Row(name='Bob', age=5)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(df.join)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e261bbda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+------+------+----+---+----+\n",
      "| id|name|gender|salary|Dept| id|Name|\n",
      "+---+----+------+------+----+---+----+\n",
      "|  2|manu|  male|  3000|   1|  1|  IT|\n",
      "|  1|srik|  male|  2000|   2|  2|  HR|\n",
      "+---+----+------+------+----+---+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.join(df1,df.Dept==df1.id,'inner').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "66e6ee3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+------+------+----+----+----+\n",
      "| id|     name|gender|salary|Dept|  id|Name|\n",
      "+---+---------+------+------+----+----+----+\n",
      "|  2|     manu|  male|  3000|   1|   1|  IT|\n",
      "|  1|     srik|  male|  2000|   2|   2|  HR|\n",
      "|  3|Akshainie|Female|  3000|   4|null|null|\n",
      "+---+---------+------+------+----+----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.join(df1,df.Dept==df1.id, 'left').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "77747e67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+------+------+----+---+-------+\n",
      "|  id|name|gender|salary|Dept| id|   Name|\n",
      "+----+----+------+------+----+---+-------+\n",
      "|   2|manu|  male|  3000|   1|  1|     IT|\n",
      "|   1|srik|  male|  2000|   2|  2|     HR|\n",
      "|null|null|  null|  null|null|  3|Payroll|\n",
      "+----+----+------+------+----+---+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.join(df1,df.Dept==df1.id, 'right').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "72761c53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+------+------+----+---+-------+\n",
      "| id|     name|gender|salary|Dept| id|   Name|\n",
      "+---+---------+------+------+----+---+-------+\n",
      "|  1|     srik|  male|  2000|   2|  1|     IT|\n",
      "|  2|     manu|  male|  3000|   1|  2|     HR|\n",
      "|  3|Akshainie|Female|  3000|   4|  3|Payroll|\n",
      "+---+---------+------+------+----+---+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.join(df1,df.id==df1.id, 'full').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f85774bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+------+------+----+---+----+\n",
      "| id|name|gender|salary|Dept| id|Name|\n",
      "+---+----+------+------+----+---+----+\n",
      "|  2|manu|  male|  3000|   1|  1|  IT|\n",
      "|  1|srik|  male|  2000|   2|  2|  HR|\n",
      "+---+----+------+------+----+---+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.join(df1,df.Dept==df1.id,'inner').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "897b495f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+------+------+----+\n",
      "| id|name|gender|salary|Dept|\n",
      "+---+----+------+------+----+\n",
      "|  2|manu|  male|  3000|   1|\n",
      "|  1|srik|  male|  2000|   2|\n",
      "+---+----+------+------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.join(df1,df.Dept==df1.id, 'leftsemi').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d3915b0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+------+------+----+\n",
      "| id|     name|gender|salary|Dept|\n",
      "+---+---------+------+------+----+\n",
      "|  3|Akshainie|Female|  3000|   4|\n",
      "+---+---------+------+------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.join(df1,df.Dept==df1.id, 'leftanti').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0ed2de85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+---------+\n",
      "| id|     name|managerid|\n",
      "+---+---------+---------+\n",
      "|  1| srikanth|        0|\n",
      "|  2|     manu|        1|\n",
      "|  3|Akshainie|        2|\n",
      "+---+---------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data1 = [(1,'srikanth',0),(2,'manu',1),(3,'Akshainie',2)]\n",
    "schema1= ['id','name','managerid']\n",
    "\n",
    "df = spark.createDataFrame(data1,schema1)\n",
    "\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "911a9a73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+---------+---+--------+---------+\n",
      "| id|     name|managerid| id|    name|managerid|\n",
      "+---+---------+---------+---+--------+---------+\n",
      "|  2|     manu|        1|  1|srikanth|        0|\n",
      "|  3|Akshainie|        2|  2|    manu|        1|\n",
      "+---+---------+---------+---+--------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "df.alias('emp').join(df.alias('mgr'),\\\n",
    "                col('emp.managerid')==col('mgr.id') \\\n",
    "                     ,'inner').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "eaf2f436",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+\n",
      "| emp_name| manager|\n",
      "+---------+--------+\n",
      "|     manu|srikanth|\n",
      "|Akshainie|    manu|\n",
      "+---------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df.alias('emp').join(df.alias('mgr'),\\\n",
    "                col('emp.managerid')==col('mgr.id') \\\n",
    "                     ,'inner') \\\n",
    "              .select(col('emp.name').alias('emp_name'),\\\n",
    "                col('mgr.name').alias('manager')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b11787d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
