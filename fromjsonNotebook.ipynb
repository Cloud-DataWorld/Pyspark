{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae46c534",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "\n",
    "findspark.init()\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark =  SparkSession.builder.getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7c66e37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------------------------+\n",
      "|id      |props                         |\n",
      "+--------+------------------------------+\n",
      "|srikanth|{\"hair\":\"black\",\"eye\":\"brown\"}|\n",
      "+--------+------------------------------+\n",
      "\n",
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- props: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = [('srikanth','{\"hair\":\"black\",\"eye\":\"brown\"}')]\n",
    "\n",
    "schema = ['id','props']\n",
    "\n",
    "df = spark.createDataFrame(data,schema)\n",
    "\n",
    "df.show(truncate=False)\n",
    "\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "511fd8ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function from_json in module pyspark.sql.functions:\n",
      "\n",
      "from_json(col, schema, options=None)\n",
      "    Parses a column containing a JSON string into a :class:`MapType` with :class:`StringType`\n",
      "    as keys type, :class:`StructType` or :class:`ArrayType` with\n",
      "    the specified schema. Returns `null`, in the case of an unparseable string.\n",
      "    \n",
      "    .. versionadded:: 2.1.0\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    col : :class:`~pyspark.sql.Column` or str\n",
      "        string column in json format\n",
      "    schema : :class:`DataType` or str\n",
      "        a StructType or ArrayType of StructType to use when parsing the json column.\n",
      "    \n",
      "        .. versionchanged:: 2.3\n",
      "            the DDL-formatted string is also supported for ``schema``.\n",
      "    options : dict, optional\n",
      "        options to control parsing. accepts the same options as the json datasource.\n",
      "        See `Data Source Option <https://spark.apache.org/docs/latest/sql-data-sources-json.html#data-source-option>`_\n",
      "        in the version you use.\n",
      "    \n",
      "        .. # noqa\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> from pyspark.sql.types import *\n",
      "    >>> data = [(1, '''{\"a\": 1}''')]\n",
      "    >>> schema = StructType([StructField(\"a\", IntegerType())])\n",
      "    >>> df = spark.createDataFrame(data, (\"key\", \"value\"))\n",
      "    >>> df.select(from_json(df.value, schema).alias(\"json\")).collect()\n",
      "    [Row(json=Row(a=1))]\n",
      "    >>> df.select(from_json(df.value, \"a INT\").alias(\"json\")).collect()\n",
      "    [Row(json=Row(a=1))]\n",
      "    >>> df.select(from_json(df.value, \"MAP<STRING,INT>\").alias(\"json\")).collect()\n",
      "    [Row(json={'a': 1})]\n",
      "    >>> data = [(1, '''[{\"a\": 1}]''')]\n",
      "    >>> schema = ArrayType(StructType([StructField(\"a\", IntegerType())]))\n",
      "    >>> df = spark.createDataFrame(data, (\"key\", \"value\"))\n",
      "    >>> df.select(from_json(df.value, schema).alias(\"json\")).collect()\n",
      "    [Row(json=[Row(a=1)])]\n",
      "    >>> schema = schema_of_json(lit('''{\"a\": 0}'''))\n",
      "    >>> df.select(from_json(df.value, schema).alias(\"json\")).collect()\n",
      "    [Row(json=Row(a=None))]\n",
      "    >>> data = [(1, '''[1, 2, 3]''')]\n",
      "    >>> schema = ArrayType(IntegerType())\n",
      "    >>> df = spark.createDataFrame(data, (\"key\", \"value\"))\n",
      "    >>> df.select(from_json(df.value, schema).alias(\"json\")).collect()\n",
      "    [Row(json=[1, 2, 3])]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#from_json function allows you to convert maptype() or structtype()\n",
    "\n",
    "from pyspark.sql.functions import from_json\n",
    "\n",
    "help(from_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a1319b9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------------------------+-----------------------------+\n",
      "|id      |props                         |propsMap                     |\n",
      "+--------+------------------------------+-----------------------------+\n",
      "|srikanth|{\"hair\":\"black\",\"eye\":\"brown\"}|{hair -> black, eye -> brown}|\n",
      "+--------+------------------------------+-----------------------------+\n",
      "\n",
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- props: string (nullable = true)\n",
      " |-- propsMap: map (nullable = true)\n",
      " |    |-- key: string\n",
      " |    |-- value: string (valueContainsNull = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import MapType,StringType\n",
    "\n",
    "MapTypeSchema = MapType(StringType(),StringType())\n",
    "\n",
    "df1 = df.withColumn('propsMap',from_json(df.props,MapTypeSchema))\n",
    "\n",
    "df1.show(truncate=False)\n",
    "\n",
    "df1.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "092bb16d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------------------------+-----------------------------+-----+-----+\n",
      "|id      |props                         |propsMap                     |HAIR |EYE  |\n",
      "+--------+------------------------------+-----------------------------+-----+-----+\n",
      "|srikanth|{\"hair\":\"black\",\"eye\":\"brown\"}|{hair -> black, eye -> brown}|black|brown|\n",
      "+--------+------------------------------+-----------------------------+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2 = df1.withColumn('HAIR',df1.propsMap.hair).\\\n",
    "          withColumn('EYE',df1.propsMap.eye)\n",
    "\n",
    "df2.show(truncate= False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ecfa5bd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+--------------+\n",
      "|      id|               props|   propsstruck|\n",
      "+--------+--------------------+--------------+\n",
      "|srikanth|{\"hair\":\"black\",\"...|{black, brown}|\n",
      "+--------+--------------------+--------------+\n",
      "\n",
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- props: string (nullable = true)\n",
      " |-- propsstruck: struct (nullable = true)\n",
      " |    |-- hair: string (nullable = true)\n",
      " |    |-- eye: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#from_json string into StructType\n",
    "\n",
    "from pyspark.sql.functions import from_json\n",
    "from pyspark.sql.types import StringType,StructField,StructType\n",
    "\n",
    "structTypeSchema =  StructType([\\\n",
    "                               StructField('hair',StringType()),\\\n",
    "                               StructField('eye',StringType())])\n",
    "\n",
    "df1 = df.withColumn('propsstruck',from_json(df.props,structTypeSchema))\n",
    "\n",
    "df1.show()\n",
    "\n",
    "df1.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "18a1b996",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+--------------+-----+-----+\n",
      "|      id|               props|   propsstruck| hair|  eye|\n",
      "+--------+--------------------+--------------+-----+-----+\n",
      "|srikanth|{\"hair\":\"black\",\"...|{black, brown}|black|brown|\n",
      "+--------+--------------------+--------------+-----+-----+\n",
      "\n",
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- props: string (nullable = true)\n",
      " |-- propsstruck: struct (nullable = true)\n",
      " |    |-- hair: string (nullable = true)\n",
      " |    |-- eye: string (nullable = true)\n",
      " |-- hair: string (nullable = true)\n",
      " |-- eye: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2 = df1.withColumn('hair',df1.propsstruck.hair) \\\n",
    "      .withColumn('eye',df1.propsstruck.eye)\n",
    "\n",
    "df2.show()\n",
    "\n",
    "df2.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e063a90d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
